# Digit_Recognition

With reference to Samson Zhang’s code and 3Blue1Brown’s detailed explanation of Neural Networks, we will build a Neural Network from scratch to predict digits using NumPy, Pandas, and Matplotlib.

The primary focus of this notebook is to develop a deep understanding of the mathematical foundations behind Neural Networks, particularly through the lens of Linear Algebra and Multivariate Calculus. We will rigorously derive key equations for Forward Propagation, Backpropagation, and Gradient Descent, emphasizing concepts such as matrix operations, partial derivatives, and the chain rule.

By the end of this notebook, you will gain a strong intuition for how Neural Networks function beyond just implementation, bridging the gap between theory and practice.

The content of this notebook:

1. Data Exploration
    - 1.1 Importing Libraries and Understanding the Data
    - 1.2 Normalisation
    
2. Introduction to Neural Network
    - 2.1 Simple Neural Network Illustration
    - 2.2 Activation Function
    - 2.3 Forward Propagation: Mathematical Notation
    - 2.4 Softmax Function (Used for Classification Problem)

3. Fine-Tuning Process (Mathematical Derivation)
    - 3.1 Cost Function
    - 3.2 Gradient Descent and Its Basis in Multivariate Calculus
    - 3.3 Backward Propagation: Mathematical Notation and Derivation

4. Applying the concepts to the Dataset
    - 4.1 Understanding the Data and Its Dimensions
    - 4.2 Forward Propagation Implementation
    - 4.3 Backward Propagation Implementation
    - 4.4 Applying the code on the Dataset

Youtube Links
- Samson Zhang code: https://www.youtube.com/watch?v=w8yWXqWQYmU&t=1745s
- 3Blue1Brown: https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi 

Dataset Used: https://www.kaggle.com/c/digit-recognizer/overview
